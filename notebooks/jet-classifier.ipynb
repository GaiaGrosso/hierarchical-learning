{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237923b6-1767-43e9-9aaf-b21fc49f1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader \n",
    "from timm.utils import ModelEmaV3 #pip install timm \n",
    "\n",
    "import matplotlib.pyplot as plt #pip install matplotlib\n",
    "import matplotlib.font_manager as font_manager\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.style.use('classic')\n",
    "font = font_manager.FontProperties(family='serif', size=16)\n",
    "\n",
    "import numpy as np\n",
    "import math, os, random, h5py\n",
    "from einops import rearrange #pip install einops\n",
    "from typing import List\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm #pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa404bde-82bf-4ffb-8991-d7d4dce62977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "            upscale: bool, \n",
    "            attention: bool, \n",
    "            num_groups: int, \n",
    "            dropout_prob: float,\n",
    "            num_heads: int,\n",
    "            C: int):\n",
    "        super().__init__()\n",
    "        self.ResBlock1 = ResBlock(C=C, num_groups=num_groups, dropout_prob=dropout_prob)\n",
    "        self.ResBlock2 = ResBlock(C=C, num_groups=num_groups, dropout_prob=dropout_prob)\n",
    "        if upscale:\n",
    "            self.conv = nn.ConvTranspose2d(C, C//2, kernel_size=4, stride=2, padding=1)\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(C, C*2, kernel_size=3, stride=2, padding=1)\n",
    "        if attention:\n",
    "            self.attention_layer = Attention(C, num_heads=num_heads, dropout_prob=dropout_prob)\n",
    "\n",
    "    def forward(self, x, embeddings):\n",
    "        x = self.ResBlock1(x, embeddings)\n",
    "        if hasattr(self, 'attention_layer'):\n",
    "            x = self.attention_layer(x)\n",
    "        x = self.ResBlock2(x, embeddings)\n",
    "        return self.conv(x), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4200e42c-1f9a-431c-a82e-27d125822725",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, C: int, num_groups: int, dropout_prob: float):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.gnorm1 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
    "        self.gnorm2 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n",
    "        self.conv1 = nn.Conv2d(C, C, kernel_size=3, padding=1, padding_mode='circular')\n",
    "        self.conv2 = nn.Conv2d(C, C, kernel_size=3, padding=1, padding_mode='circular')\n",
    "        self.dropout = nn.Dropout(p=dropout_prob, inplace=True)\n",
    "\n",
    "    def forward(self, x, embeddings):\n",
    "        x = x + embeddings[:, :x.shape[1], :, :]\n",
    "        r = self.conv1(self.relu(self.gnorm1(x)))\n",
    "        r = self.dropout(r)\n",
    "        r = self.conv2(self.relu(self.gnorm2(r)))\n",
    "        return r + x\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, h_sizes, out_size):\n",
    "        ...\n",
    "        # Hidden layers\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for k in range(len(h_sizes)-1):\n",
    "            self.hidden.append(nn.Linear(h_sizes[k], h_sizes[k+1]))\n",
    "        # Output layer\n",
    "        self.out = nn.Linear(h_sizes[-1], out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feedforward\n",
    "        for layer in self.hidden:\n",
    "            x = F.relu(layer(x))\n",
    "        output= F.softmax(self.out(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18623d4f-5854-4853-91c6-6c9903c2b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalEmbeddings(nn.Module):\n",
    "    def __init__(self, time_steps:int, embed_dim: int):\n",
    "        super().__init__()\n",
    "        position = torch.arange(time_steps).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, embed_dim, 2).float() * -(math.log(10000.0) / embed_dim))\n",
    "        embeddings = torch.zeros(time_steps, embed_dim, requires_grad=False)\n",
    "        embeddings[:, 0::2] = torch.sin(position * div)\n",
    "        embeddings[:, 1::2] = torch.cos(position * div)\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        embeds = self.embeddings[t].to(x.device)\n",
    "        return embeds[:, :, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c71229c-c966-410e-a5a5-aedc74f9e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET_classifier(nn.Module):\n",
    "    def __init__(self,\n",
    "            Channels: List = [64, 128, 256, 512, 512, 384],\n",
    "            Attentions: List = [False, True, False, False, False, True],\n",
    "            Upscales: List = [False, False, False, True, True, True],\n",
    "            num_groups: int = 32,\n",
    "            dropout_prob: float = 0.1,\n",
    "            num_heads: int = 8,\n",
    "            input_channels: int = 1,\n",
    "            output_channels: int = 1,\n",
    "            time_steps: int = 1000,\n",
    "             MLP_h_sizes: int=50,\n",
    "             MLP_out_size: int=3,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.num_layers = len(Channels)\n",
    "        self.shallow_conv = nn.Conv2d(input_channels, Channels[0], kernel_size=3, padding=1)\n",
    "        out_channels = (Channels[-1]//2)+Channels[0]\n",
    "        self.late_conv = nn.Conv2d(out_channels, out_channels//2, kernel_size=3, padding=1)\n",
    "        self.output_conv = nn.Conv2d(out_channels//2, output_channels, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.embeddings = SinusoidalEmbeddings(time_steps=time_steps, embed_dim=max(Channels))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.MLP_output = MLPBlock(MLP_h_sizes, MLP_out_size)\n",
    "        for i in range(self.num_layers):\n",
    "            layer = UnetLayer(\n",
    "                upscale=Upscales[i],\n",
    "                attention=Attentions[i],\n",
    "                num_groups=num_groups,\n",
    "                dropout_prob=dropout_prob,\n",
    "                C=Channels[i],\n",
    "                num_heads=num_heads\n",
    "            )\n",
    "            setattr(self, f'Layer{i+1}', layer)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.shallow_conv(x)\n",
    "        residuals = []\n",
    "        for i in range(self.num_layers//2):\n",
    "            layer = getattr(self, f'Layer{i+1}')\n",
    "            embeddings = self.embeddings(x, t)\n",
    "            x, r = layer(x, embeddings)\n",
    "            residuals.append(r)\n",
    "        for i in range(self.num_layers//2, self.num_layers):\n",
    "            layer = getattr(self, f'Layer{i+1}')\n",
    "            x = torch.concat((layer(x, embeddings)[0], residuals[self.num_layers-i-1]), dim=1)\n",
    "        x = self.output_conv(self.relu(self.late_conv(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.MLP_output(x)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc0c724d-48c8-4262-8613-3e869272c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "def npy_loader(paths, input_dim=64):\n",
    "    samples = []\n",
    "    for path in paths:\n",
    "        sample = torch.from_numpy(np.load(path))\n",
    "        if len(sample.shape)==3:\n",
    "            sample = sample[:, None, :, :]\n",
    "        if sample.shape[-1]>input_dim:\n",
    "            sample = transforms.CenterCrop(input_dim)(sample)\n",
    "        print(sample.shape)\n",
    "        print(type(sample))\n",
    "        samples.append(sample)\n",
    "    samples=torch.cat(samples, dim=0)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e51d3-67a6-4f1f-97e5-0dbe96c5cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_dataset, batch_size: int=32, \n",
    "    num_time_steps: int=1000, \n",
    "    num_epochs: int=15, \n",
    "    save_patience: int=1,\n",
    "    seed: int=-1, \n",
    "    ema_decay: float=0.9999,  \n",
    "    lr=2e-5, \n",
    "    checkpoint_folder_path: str=None, \n",
    "    checkpoint_filename: str=None, input_dim: int=32,\n",
    "    unet_Channels: List=[64, 128, 256, 512, 512, 384],\n",
    "    unet_Attentions: List = [False, True, False, False, False, True],\n",
    "    unet_Upscales: List = [False, False, False, True, True, True],\n",
    "    unet_num_groups: List = 32,\n",
    "    unet_dropout_prob: List = 0.1,\n",
    "    unet_num_heads: List = 8,\n",
    "    unet_input_channels: List = 1,\n",
    "    unet_output_channels: List = 1,\n",
    "    unet_MLP_h_sizes: int=50,\n",
    "    unet_MLP_out_size: int=3,\n",
    "         ):\n",
    "    \n",
    "    set_seed(random.randint(0, 2**32-1)) if seed == -1 else set_seed(seed)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=4)\n",
    "    \n",
    "    # define scheduler\n",
    "    scheduler = DDPM_Scheduler(num_time_steps=num_time_steps)\n",
    "    \n",
    "    # define models\n",
    "    model = UNET_classifier(\n",
    "            unet_Channels,\n",
    "            unet_Attentions,\n",
    "            unet_Upscales,\n",
    "            unet_num_groups,\n",
    "            unet_dropout_prob,\n",
    "            unet_num_heads,\n",
    "            unet_input_channels,\n",
    "            unet_output_channels,\n",
    "            unet_MLP_h_sizes,\n",
    "            unet_MLP_out_size\n",
    "    ).cuda()\n",
    "    # exponential moving average (ema)\n",
    "    # When training a model, it is often beneficial to maintain moving averages of the trained parameters. \n",
    "    # Evaluations that use averaged parameters sometimes produce significantly better results than the final trained values.\n",
    "    ema = ModelEmaV3(model, decay=ema_decay)\n",
    "    \n",
    "    # define optmizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # load checkpoint if present\n",
    "    if os.path.exists(checkpoint_folder_path+'/'+checkpoint_filename):\n",
    "        print('Loading previous checkpoint')\n",
    "        checkpoint = torch.load(checkpoint_folder_path+'/'+checkpoint_filename)\n",
    "        model.load_state_dict(checkpoint['weights'])\n",
    "        ema.load_state_dict(checkpoint['ema'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    else:\n",
    "        os.makedirs(checkpoint_folder_path, exist_ok=True)\n",
    "    # define loss\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    # start the training\n",
    "    for i in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for bidx, x in enumerate(tqdm(train_loader, desc=f\"Epoch {i+1}/{num_epochs}\")):\n",
    "            x = x.cuda()\n",
    "            x = F.pad(x, (2,2,2,2))\n",
    "            \n",
    "            # FORWARD PROCESS\n",
    "            # pick a random time step (t)\n",
    "            t = torch.randint(0,num_time_steps,(batch_size,))\n",
    "            # generate noise (e)\n",
    "            e = torch.randn_like(x, requires_grad=False)\n",
    "            # define the scheduler at time t (alpha_t)\n",
    "            a = scheduler.alpha[t].view(batch_size,1,1,1).cuda()\n",
    "            # update x: x(0) --> x(t)\n",
    "            x = (torch.sqrt(a)*x) + (torch.sqrt(1-a)*e)\n",
    "\n",
    "            # NOISE MATCHING\n",
    "            output = model(x, t)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, e)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ema.update(model)\n",
    "        print(f'Epoch {i+1} | Loss {total_loss / (60000/batch_size):.5f}')\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if (not i%save_patience) or (i==(num_epochs-1)):\n",
    "            print(\"Save checkpoint %i\"%(i))\n",
    "            # save model at the end of each epoch\n",
    "            checkpoint = {\n",
    "                'weights': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'ema': ema.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, checkpoint_folder_path+'/'+checkpoint_filename+'_%i'%(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
